# =============================================================================
# Anomaly Detection Pipeline - Environment Configuration
# =============================================================================
# Copy this file to .env and fill in your values

# -----------------------------------------------------------------------------
# Model Paths (Required)
# -----------------------------------------------------------------------------

# Path to SAM3 model checkpoint
# Download from: https://github.com/facebookresearch/sam3
# Available models:
#   - sam3_hiera_tiny.pt    (fastest, lower quality)
#   - sam3_hiera_small.pt
#   - sam3_hiera_base.pt
#   - sam3_hiera_large.pt   (best quality, slower)
ANOMALY_SEGMENTER_MODEL=weights/sam3_hiera_large.pt

# Path to RF-DETR detector weights (optional - uses pretrained if not set)
# Train your own or use pretrained from: https://github.com/roboflow/rf-detr
ANOMALY_DETECTOR_MODEL=

# -----------------------------------------------------------------------------
# Device Configuration
# -----------------------------------------------------------------------------

# Device to use: "auto", "cuda", "cuda:0", "cuda:1", "cpu"
ANOMALY_DEVICE=auto

# -----------------------------------------------------------------------------
# Detection Settings
# -----------------------------------------------------------------------------

# Confidence threshold for detections (0.0 - 1.0)
ANOMALY_CONFIDENCE_THRESHOLD=0.3

# -----------------------------------------------------------------------------
# Output Settings
# -----------------------------------------------------------------------------

# Directory to save segmentation masks (optional)
ANOMALY_MASK_OUTPUT_DIR=output/masks

# -----------------------------------------------------------------------------
# VLM Judge Configuration (Optional)
# -----------------------------------------------------------------------------

# Enable VLM judge for additional anomaly guidance
ENABLE_VLM_JUDGE=false

# VLM Provider: "local" or "openrouter"
VLM_PROVIDER=local

# For local Qwen model - path to model or HuggingFace model ID
QWEN_MODEL_PATH=Qwen/Qwen2.5-VL-7B-Instruct

# For OpenRouter API
OPENROUTER_API_KEY=sk-or-v1-xxxxxxxxxxxxxxxxxxxx
OPENROUTER_MODEL=qwen/qwen-2.5-vl-72b-instruct

# VLM processing frequency (process every N frames)
VLM_EVERY_N_FRAMES=10

# Max frames to wait for VLM response before discarding
VLM_MAX_GENERATION_FRAMES=60

# -----------------------------------------------------------------------------
# Web Server Configuration
# -----------------------------------------------------------------------------

# Server host and port
WEB_HOST=0.0.0.0
WEB_PORT=8000

# -----------------------------------------------------------------------------
# Video Processing Settings
# -----------------------------------------------------------------------------

# Target FPS for video processing
TARGET_FPS=30

# Frame buffer size (number of frames to buffer)
FRAME_BUFFER_SIZE=120

# Enable image tiling for large images
ENABLE_TILING=true
